{"nbformat_minor": 1, "cells": [{"cell_type": "markdown", "metadata": {"collapsed": true}, "source": "Reference https://keras.io/getting-started/sequential-model-guide/\n"}, {"cell_type": "code", "metadata": {}, "source": "# Prepare TensorFlow backend\n!pip install tensorflow", "execution_count": 8, "outputs": [{"name": "stdout", "output_type": "stream", "text": "Requirement already satisfied (use --upgrade to upgrade): tensorflow in /usr/local/src/conda3_runtime.v15/4.1.1/lib/python3.5/site-packages\nRequirement already satisfied (use --upgrade to upgrade): backports.weakref==1.0rc1 in /usr/local/src/conda3_runtime.v15/4.1.1/lib/python3.5/site-packages (from tensorflow)\nRequirement already satisfied (use --upgrade to upgrade): markdown>=2.6.8 in /usr/local/src/conda3_runtime.v15/4.1.1/lib/python3.5/site-packages (from tensorflow)\nRequirement already satisfied (use --upgrade to upgrade): protobuf>=3.2.0 in /gpfs/global_fs01/sym_shared/YPProdSpark/user/s558-b5a8b8675190f4-11adb48ea25c/.local/lib/python3.5/site-packages (from tensorflow)\nRequirement already satisfied (use --upgrade to upgrade): werkzeug>=0.11.10 in /usr/local/src/conda3_runtime.v15/4.1.1/lib/python3.5/site-packages (from tensorflow)\nRequirement already satisfied (use --upgrade to upgrade): html5lib==0.9999999 in /gpfs/global_fs01/sym_shared/YPProdSpark/user/s558-b5a8b8675190f4-11adb48ea25c/.local/lib/python3.5/site-packages (from tensorflow)\nRequirement already satisfied (use --upgrade to upgrade): six>=1.10.0 in /usr/local/src/conda3_runtime.v15/4.1.1/lib/python3.5/site-packages (from tensorflow)\nRequirement already satisfied (use --upgrade to upgrade): bleach==1.5.0 in /gpfs/global_fs01/sym_shared/YPProdSpark/user/s558-b5a8b8675190f4-11adb48ea25c/.local/lib/python3.5/site-packages (from tensorflow)\nRequirement already satisfied (use --upgrade to upgrade): numpy>=1.11.0 in /usr/local/src/conda3_runtime.v15/4.1.1/lib/python3.5/site-packages (from tensorflow)\nRequirement already satisfied (use --upgrade to upgrade): wheel>=0.26 in /usr/local/src/conda3_runtime.v15/4.1.1/lib/python3.5/site-packages (from tensorflow)\nRequirement already satisfied (use --upgrade to upgrade): setuptools in /usr/local/src/conda3_runtime.v15/4.1.1/lib/python3.5/site-packages/setuptools-23.0.0-py3.5.egg (from protobuf>=3.2.0->tensorflow)\n"}]}, {"cell_type": "code", "metadata": {}, "source": "# Prepare Theano backend\n!pip install theano", "execution_count": 9, "outputs": [{"name": "stdout", "output_type": "stream", "text": "Requirement already satisfied (use --upgrade to upgrade): theano in /usr/local/src/conda3_runtime.v15/4.1.1/lib/python3.5/site-packages\r\nRequirement already satisfied (use --upgrade to upgrade): numpy>=1.7.1 in /usr/local/src/conda3_runtime.v15/4.1.1/lib/python3.5/site-packages (from theano)\r\nRequirement already satisfied (use --upgrade to upgrade): scipy>=0.11 in /usr/local/src/conda3_runtime.v15/4.1.1/lib/python3.5/site-packages (from theano)\r\nRequirement already satisfied (use --upgrade to upgrade): six>=1.9.0 in /usr/local/src/conda3_runtime.v15/4.1.1/lib/python3.5/site-packages (from theano)\r\n"}]}, {"cell_type": "code", "metadata": {}, "source": "# Install Keras\n!pip install keras\n", "execution_count": 10, "outputs": [{"name": "stdout", "output_type": "stream", "text": "Requirement already satisfied (use --upgrade to upgrade): keras in /usr/local/src/conda3_runtime.v15/4.1.1/lib/python3.5/site-packages\nRequirement already satisfied (use --upgrade to upgrade): pyyaml in /usr/local/src/conda3_runtime.v15/4.1.1/lib/python3.5/site-packages (from keras)\nRequirement already satisfied (use --upgrade to upgrade): theano in /usr/local/src/conda3_runtime.v15/4.1.1/lib/python3.5/site-packages (from keras)\nRequirement already satisfied (use --upgrade to upgrade): six in /usr/local/src/conda3_runtime.v15/4.1.1/lib/python3.5/site-packages (from keras)\nRequirement already satisfied (use --upgrade to upgrade): numpy>=1.7.1 in /usr/local/src/conda3_runtime.v15/4.1.1/lib/python3.5/site-packages (from theano->keras)\nRequirement already satisfied (use --upgrade to upgrade): scipy>=0.11 in /usr/local/src/conda3_runtime.v15/4.1.1/lib/python3.5/site-packages (from theano->keras)\n"}]}, {"cell_type": "code", "metadata": {}, "source": "# Toggle backend between TensorFlow(default) and Theano\n%env KERAS_BACKEND=theano", "execution_count": 11, "outputs": [{"name": "stdout", "output_type": "stream", "text": "env: KERAS_BACKEND=theano\n"}]}, {"cell_type": "code", "metadata": {}, "source": "from keras.models import Sequential\nfrom keras.layers import Dense, Activation\n\n# For a single-input model with 2 classes (binary classification):\n\nmodel = Sequential()\nmodel.add(Dense(32, activation='relu', input_dim=100))\nmodel.add(Dense(1, activation='sigmoid'))\nmodel.compile(optimizer='rmsprop',\n              loss='binary_crossentropy',\n              metrics=['accuracy'])\n\n# Generate dummy data\nimport numpy as np\ndata = np.random.random((1000, 100))\nlabels = np.random.randint(2, size=(1000, 1))\n\n# Train the model, iterating on the data in batches of 32 samples\nmodel.fit(data, labels, epochs=10, batch_size=32)", "execution_count": 12, "outputs": [{"name": "stdout", "output_type": "stream", "text": "Epoch 1/10\n1000/1000 [==============================] - 0s - loss: 0.7099 - acc: 0.4970      \nEpoch 2/10\n1000/1000 [==============================] - 0s - loss: 0.6972 - acc: 0.5130     \nEpoch 3/10\n1000/1000 [==============================] - 0s - loss: 0.6886 - acc: 0.5470     \nEpoch 4/10\n1000/1000 [==============================] - 0s - loss: 0.6837 - acc: 0.5600     \nEpoch 5/10\n1000/1000 [==============================] - 0s - loss: 0.6788 - acc: 0.5750     \nEpoch 6/10\n1000/1000 [==============================] - 0s - loss: 0.6751 - acc: 0.5860     \nEpoch 7/10\n1000/1000 [==============================] - 0s - loss: 0.6702 - acc: 0.5880     \nEpoch 8/10\n1000/1000 [==============================] - 0s - loss: 0.6648 - acc: 0.6040     \nEpoch 9/10\n1000/1000 [==============================] - 0s - loss: 0.6604 - acc: 0.6120     \nEpoch 10/10\n1000/1000 [==============================] - 0s - loss: 0.6583 - acc: 0.6060     \n"}, {"data": {"text/plain": "<keras.callbacks.History at 0x7f9f2469eb38>"}, "output_type": "execute_result", "metadata": {}, "execution_count": 12}]}, {"cell_type": "code", "metadata": {}, "source": "import keras\n\n# For a single-input model with 10 classes (categorical classification):\n\nmodel = Sequential()\nmodel.add(Dense(32, activation='relu', input_dim=100))\nmodel.add(Dense(10, activation='softmax'))\nmodel.compile(optimizer='rmsprop',\n              loss='categorical_crossentropy',\n              metrics=['accuracy'])\n\n# Generate dummy data\nimport numpy as np\ndata = np.random.random((1000, 100))\nlabels = np.random.randint(10, size=(1000, 1))\n\n# Convert labels to categorical one-hot encoding\none_hot_labels = keras.utils.to_categorical(labels, num_classes=10)\n\n# Train the model, iterating on the data in batches of 32 samples\nmodel.fit(data, one_hot_labels, epochs=10, batch_size=32)", "execution_count": 7, "outputs": [{"name": "stdout", "output_type": "stream", "text": "Epoch 1/10\n1000/1000 [==============================] - 0s - loss: 2.3483 - acc: 0.1130     \nEpoch 2/10\n1000/1000 [==============================] - 0s - loss: 2.3167 - acc: 0.1090     \nEpoch 3/10\n1000/1000 [==============================] - 0s - loss: 2.3031 - acc: 0.1310     \nEpoch 4/10\n1000/1000 [==============================] - 0s - loss: 2.2958 - acc: 0.1170     \nEpoch 5/10\n1000/1000 [==============================] - 0s - loss: 2.2873 - acc: 0.1280     \nEpoch 6/10\n1000/1000 [==============================] - 0s - loss: 2.2791 - acc: 0.1400     \nEpoch 7/10\n1000/1000 [==============================] - 0s - loss: 2.2731 - acc: 0.1380     \nEpoch 8/10\n1000/1000 [==============================] - 0s - loss: 2.2659 - acc: 0.1400     \nEpoch 9/10\n1000/1000 [==============================] - 0s - loss: 2.2599 - acc: 0.1520     \nEpoch 10/10\n1000/1000 [==============================] - 0s - loss: 2.2535 - acc: 0.1530     \n"}, {"data": {"text/plain": "<keras.callbacks.History at 0x7fc284454ba8>"}, "output_type": "execute_result", "metadata": {}, "execution_count": 7}]}, {"cell_type": "markdown", "metadata": {}, "source": "### Example: Multilayer Perceptron (MLP) for multi-class softmax classification\n"}, {"cell_type": "code", "metadata": {}, "source": "from keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Activation\nfrom keras.optimizers import SGD\n\n# Generate dummy data\nimport numpy as np\nx_train = np.random.random((1000, 20))\ny_train = keras.utils.to_categorical(np.random.randint(10, size=(1000, 1)), num_classes=10)\nx_test = np.random.random((100, 20))\ny_test = keras.utils.to_categorical(np.random.randint(10, size=(100, 1)), num_classes=10)\n\nmodel = Sequential()\n# Dense(64) is a fully-connected layer with 64 hidden units.\n# in the first layer, you must specify the expected input data shape:\n# here, 20-dimensional vectors.\nmodel.add(Dense(64, activation='relu', input_dim=20))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(64, activation='relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(10, activation='softmax'))\n\nsgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\nmodel.compile(loss='categorical_crossentropy',\n              optimizer=sgd,\n              metrics=['accuracy'])\n\nmodel.fit(x_train, y_train,\n          epochs=20,\n          batch_size=128)\nscore = model.evaluate(x_test, y_test, batch_size=128)", "execution_count": 8, "outputs": [{"name": "stdout", "output_type": "stream", "text": "Epoch 1/20\n1000/1000 [==============================] - 0s - loss: 2.3955 - acc: 0.1040     \nEpoch 2/20\n1000/1000 [==============================] - 0s - loss: 2.3517 - acc: 0.1200     \nEpoch 3/20\n1000/1000 [==============================] - 0s - loss: 2.3401 - acc: 0.1070     \nEpoch 4/20\n1000/1000 [==============================] - 0s - loss: 2.3193 - acc: 0.1010     \nEpoch 5/20\n1000/1000 [==============================] - 0s - loss: 2.3210 - acc: 0.0930     \nEpoch 6/20\n1000/1000 [==============================] - 0s - loss: 2.3061 - acc: 0.1200     \nEpoch 7/20\n1000/1000 [==============================] - 0s - loss: 2.3088 - acc: 0.1110     \nEpoch 8/20\n1000/1000 [==============================] - 0s - loss: 2.3082 - acc: 0.1150     \nEpoch 9/20\n1000/1000 [==============================] - 0s - loss: 2.3059 - acc: 0.1070     \nEpoch 10/20\n1000/1000 [==============================] - 0s - loss: 2.3056 - acc: 0.1200     \nEpoch 11/20\n1000/1000 [==============================] - 0s - loss: 2.3045 - acc: 0.1180     \nEpoch 12/20\n1000/1000 [==============================] - 0s - loss: 2.2924 - acc: 0.1290     \nEpoch 13/20\n1000/1000 [==============================] - 0s - loss: 2.2928 - acc: 0.1140     \nEpoch 14/20\n1000/1000 [==============================] - 0s - loss: 2.2962 - acc: 0.0990     \nEpoch 15/20\n1000/1000 [==============================] - 0s - loss: 2.3014 - acc: 0.1160     \nEpoch 16/20\n1000/1000 [==============================] - 0s - loss: 2.3018 - acc: 0.0920     \nEpoch 17/20\n1000/1000 [==============================] - 0s - loss: 2.2955 - acc: 0.1320     \nEpoch 18/20\n1000/1000 [==============================] - 0s - loss: 2.2931 - acc: 0.1230     \nEpoch 19/20\n1000/1000 [==============================] - 0s - loss: 2.2940 - acc: 0.1230     \nEpoch 20/20\n1000/1000 [==============================] - 0s - loss: 2.2946 - acc: 0.1150     \n100/100 [==============================] - 0s\n"}]}, {"cell_type": "markdown", "metadata": {}, "source": "### Example: MLP for binary classification\n"}, {"cell_type": "code", "metadata": {}, "source": "import numpy as np\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout\n\n# Generate dummy data\nx_train = np.random.random((1000, 20))\ny_train = np.random.randint(2, size=(1000, 1))\nx_test = np.random.random((100, 20))\ny_test = np.random.randint(2, size=(100, 1))\n\nmodel = Sequential()\nmodel.add(Dense(64, input_dim=20, activation='relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(64, activation='relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(1, activation='sigmoid'))\n\nmodel.compile(loss='binary_crossentropy',\n              optimizer='rmsprop',\n              metrics=['accuracy'])\n\nmodel.fit(x_train, y_train,\n          epochs=20,\n          batch_size=128)\nscore = model.evaluate(x_test, y_test, batch_size=128)", "execution_count": 9, "outputs": [{"name": "stdout", "output_type": "stream", "text": "Epoch 1/20\n1000/1000 [==============================] - 0s - loss: 0.7186 - acc: 0.4920     \nEpoch 2/20\n1000/1000 [==============================] - 0s - loss: 0.7054 - acc: 0.5150     \nEpoch 3/20\n1000/1000 [==============================] - 0s - loss: 0.7072 - acc: 0.4900     \nEpoch 4/20\n1000/1000 [==============================] - 0s - loss: 0.7062 - acc: 0.4770     \nEpoch 5/20\n1000/1000 [==============================] - 0s - loss: 0.7027 - acc: 0.5090     \nEpoch 6/20\n1000/1000 [==============================] - 0s - loss: 0.6981 - acc: 0.5320     \nEpoch 7/20\n1000/1000 [==============================] - 0s - loss: 0.7002 - acc: 0.4980     \nEpoch 8/20\n1000/1000 [==============================] - 0s - loss: 0.6932 - acc: 0.5310     \nEpoch 9/20\n1000/1000 [==============================] - 0s - loss: 0.6957 - acc: 0.5360     \nEpoch 10/20\n1000/1000 [==============================] - 0s - loss: 0.6924 - acc: 0.5140     \nEpoch 11/20\n1000/1000 [==============================] - 0s - loss: 0.6933 - acc: 0.5330     \nEpoch 12/20\n1000/1000 [==============================] - 0s - loss: 0.6969 - acc: 0.5040     \nEpoch 13/20\n1000/1000 [==============================] - 0s - loss: 0.6976 - acc: 0.5220     \nEpoch 14/20\n1000/1000 [==============================] - 0s - loss: 0.6955 - acc: 0.5180     \nEpoch 15/20\n1000/1000 [==============================] - 0s - loss: 0.6923 - acc: 0.5220     \nEpoch 16/20\n1000/1000 [==============================] - 0s - loss: 0.6946 - acc: 0.5040     \nEpoch 17/20\n1000/1000 [==============================] - 0s - loss: 0.6941 - acc: 0.5250     \nEpoch 18/20\n1000/1000 [==============================] - 0s - loss: 0.6946 - acc: 0.5140     \nEpoch 19/20\n1000/1000 [==============================] - 0s - loss: 0.6908 - acc: 0.5360     \nEpoch 20/20\n1000/1000 [==============================] - 0s - loss: 0.6957 - acc: 0.5140     \n100/100 [==============================] - 0s\n"}]}, {"cell_type": "markdown", "metadata": {}, "source": "### VGG-like convnet"}, {"cell_type": "code", "metadata": {}, "source": "import numpy as np\nimport keras\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten\nfrom keras.layers import Conv2D, MaxPooling2D\nfrom keras.optimizers import SGD\n\n# Generate dummy data\nx_train = np.random.random((100, 100, 100, 3))\ny_train = keras.utils.to_categorical(np.random.randint(10, size=(100, 1)), num_classes=10)\nx_test = np.random.random((20, 100, 100, 3))\ny_test = keras.utils.to_categorical(np.random.randint(10, size=(20, 1)), num_classes=10)\n\nmodel = Sequential()\n# input: 100x100 images with 3 channels -> (100, 100, 3) tensors.\n# this applies 32 convolution filters of size 3x3 each.\nmodel.add(Conv2D(32, (3, 3), activation='relu', input_shape=(100, 100, 3)))\nmodel.add(Conv2D(32, (3, 3), activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))\n\nmodel.add(Conv2D(64, (3, 3), activation='relu'))\nmodel.add(Conv2D(64, (3, 3), activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))\n\nmodel.add(Flatten())\nmodel.add(Dense(256, activation='relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(10, activation='softmax'))\n\nsgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\nmodel.compile(loss='categorical_crossentropy', optimizer=sgd)\n\nmodel.fit(x_train, y_train, batch_size=32, epochs=10)\nscore = model.evaluate(x_test, y_test, batch_size=32)", "execution_count": 10, "outputs": [{"name": "stdout", "output_type": "stream", "text": "Epoch 1/10\n100/100 [==============================] - 1s - loss: 2.3381     \nEpoch 2/10\n100/100 [==============================] - 1s - loss: 2.3345     \nEpoch 3/10\n100/100 [==============================] - 1s - loss: 2.3061     \nEpoch 4/10\n100/100 [==============================] - 1s - loss: 2.3047     \nEpoch 5/10\n100/100 [==============================] - 1s - loss: 2.2816     \nEpoch 6/10\n100/100 [==============================] - 1s - loss: 2.2894     \nEpoch 7/10\n100/100 [==============================] - 1s - loss: 2.2685     \nEpoch 8/10\n100/100 [==============================] - 1s - loss: 2.2827     \nEpoch 9/10\n100/100 [==============================] - 1s - loss: 2.2625     \nEpoch 10/10\n100/100 [==============================] - 1s - loss: 2.2773     \n20/20 [==============================] - 0s\n"}]}, {"cell_type": "markdown", "metadata": {}, "source": "### Stacked LSTM for sequence classification\n"}, {"cell_type": "code", "metadata": {}, "source": "from keras.models import Sequential\nfrom keras.layers import LSTM, Dense\nimport numpy as np\n\ndata_dim = 16\ntimesteps = 8\nnum_classes = 10\n\n# expected input data shape: (batch_size, timesteps, data_dim)\nmodel = Sequential()\nmodel.add(LSTM(32, return_sequences=True,\n               input_shape=(timesteps, data_dim)))  # returns a sequence of vectors of dimension 32\nmodel.add(LSTM(32, return_sequences=True))  # returns a sequence of vectors of dimension 32\nmodel.add(LSTM(32))  # return a single vector of dimension 32\nmodel.add(Dense(10, activation='softmax'))\n\nmodel.compile(loss='categorical_crossentropy',\n              optimizer='rmsprop',\n              metrics=['accuracy'])\n\n# Generate dummy training data\nx_train = np.random.random((1000, timesteps, data_dim))\ny_train = np.random.random((1000, num_classes))\n\n# Generate dummy validation data\nx_val = np.random.random((100, timesteps, data_dim))\ny_val = np.random.random((100, num_classes))\n\nmodel.fit(x_train, y_train,\n          batch_size=64, epochs=5,\n          validation_data=(x_val, y_val))", "execution_count": 11, "outputs": [{"name": "stdout", "output_type": "stream", "text": "Train on 1000 samples, validate on 100 samples\nEpoch 1/5\n1000/1000 [==============================] - 2s - loss: 11.5014 - acc: 0.0990 - val_loss: 11.3477 - val_acc: 0.1000\nEpoch 2/5\n1000/1000 [==============================] - 0s - loss: 11.4996 - acc: 0.0950 - val_loss: 11.3472 - val_acc: 0.0900\nEpoch 3/5\n1000/1000 [==============================] - 0s - loss: 11.4991 - acc: 0.0820 - val_loss: 11.3450 - val_acc: 0.1200\nEpoch 4/5\n1000/1000 [==============================] - 0s - loss: 11.4982 - acc: 0.1090 - val_loss: 11.3446 - val_acc: 0.1100\nEpoch 5/5\n1000/1000 [==============================] - 0s - loss: 11.4979 - acc: 0.1170 - val_loss: 11.3466 - val_acc: 0.1000\n"}, {"data": {"text/plain": "<keras.callbacks.History at 0x7fbf6c92b438>"}, "output_type": "execute_result", "metadata": {}, "execution_count": 11}]}, {"cell_type": "markdown", "metadata": {}, "source": "### Same stacked LSTM model, rendered \"stateful\"\n"}, {"cell_type": "code", "metadata": {}, "source": "from keras.models import Sequential\nfrom keras.layers import LSTM, Dense\nimport numpy as np\n\ndata_dim = 16\ntimesteps = 8\nnum_classes = 10\nbatch_size = 32\n\n# Expected input batch shape: (batch_size, timesteps, data_dim)\n# Note that we have to provide the full batch_input_shape since the network is stateful.\n# the sample of index i in batch k is the follow-up for the sample i in batch k-1.\nmodel = Sequential()\nmodel.add(LSTM(32, return_sequences=True, stateful=True,\n               batch_input_shape=(batch_size, timesteps, data_dim)))\nmodel.add(LSTM(32, return_sequences=True, stateful=True))\nmodel.add(LSTM(32, stateful=True))\nmodel.add(Dense(10, activation='softmax'))\n\nmodel.compile(loss='categorical_crossentropy',\n              optimizer='rmsprop',\n              metrics=['accuracy'])\n\n# Generate dummy training data\nx_train = np.random.random((batch_size * 10, timesteps, data_dim))\ny_train = np.random.random((batch_size * 10, num_classes))\n\n# Generate dummy validation data\nx_val = np.random.random((batch_size * 3, timesteps, data_dim))\ny_val = np.random.random((batch_size * 3, num_classes))\n\nmodel.fit(x_train, y_train,\n          batch_size=batch_size, epochs=5, shuffle=False,\n          validation_data=(x_val, y_val))", "execution_count": 12, "outputs": [{"name": "stdout", "output_type": "stream", "text": "Train on 320 samples, validate on 96 samples\nEpoch 1/5\n320/320 [==============================] - 2s - loss: 11.5640 - acc: 0.0938 - val_loss: 11.4566 - val_acc: 0.1146\nEpoch 2/5\n320/320 [==============================] - 0s - loss: 11.5593 - acc: 0.1281 - val_loss: 11.4567 - val_acc: 0.1146\nEpoch 3/5\n320/320 [==============================] - 0s - loss: 11.5584 - acc: 0.1187 - val_loss: 11.4567 - val_acc: 0.1146\nEpoch 4/5\n320/320 [==============================] - 0s - loss: 11.5577 - acc: 0.1125 - val_loss: 11.4568 - val_acc: 0.1146\nEpoch 5/5\n320/320 [==============================] - 0s - loss: 11.5570 - acc: 0.1250 - val_loss: 11.4570 - val_acc: 0.1250\n"}, {"data": {"text/plain": "<keras.callbacks.History at 0x7fbf33fcc048>"}, "output_type": "execute_result", "metadata": {}, "execution_count": 12}]}, {"cell_type": "code", "metadata": {"collapsed": true}, "source": "", "execution_count": null, "outputs": []}], "metadata": {"kernelspec": {"display_name": "Python 3.5 (Experimental) with Spark 2.0", "language": "python", "name": "python3-spark20"}, "language_info": {"version": "3.5.2", "nbconvert_exporter": "python", "mimetype": "text/x-python", "pygments_lexer": "ipython3", "codemirror_mode": {"version": 3, "name": "ipython"}, "file_extension": ".py", "name": "python"}}, "nbformat": 4}